# Advent of Code 2025

- https://adventofcode.com/
- https://github.com/livexia/advent-of-code-2025

## Day 1

今天的问题算是轻松，输入的每一行决定旋钮的转向和旋转的距离，输入的处理也不复杂，但是要注意在解析数字时的错误处理，输入处理完成后，如果旋钮是向左旋转则距离为负数，向右则为正数。

第一部分只需要计算旋转之后的刻度位置是否为 0 即可，可以简单的求 100 的余数即可。

第二部分稍微复杂一些，需要计算每次旋转过程中经过了多少次 0 刻度位置，给出的测试用例较小，实际的输入旋转的距离可能是多圈的，要考虑到这一点。首先计算每一次旋转的距离至少有多少圈，每转一圈密码加一。接着计算整圈之外的旋转距离，如果起始点不在 0 ，那么旋转结束后，如果刻度跨过 0 刻度，密码加一。因为向左旋转距离是负数，如果当前位置不为 0 ，同时当前位置加上旋转距离为负数，则旋钮指针一定向左跨过一次 0 。同理如果当前位置不为 0 （不为 100），同时向右旋转，而旋转后的刻度数超过 100 ，那么指针一定向右旋转过一次 0。根据这个逻辑对 password 进行加一即可。

第二部分代码

```rust
fn part2(rotations: &[i32]) -> Result<u32> {
    let _start = Instant::now();

    let mut dial = 50;
    let mut password = 0;

    for rot in rotations {
        // 计算一定会经过 0 刻度的整圈次数
        password += rot.unsigned_abs() / 100;

        // 扣除整圈的旋转距离，
        // 可以规避例如从 0 刻度旋转距离 100 的边界情况
        let rot = rot % 100;

        let temp = dial + rot;
        // 当起点不是 0 刻度时，
        // 向左或向右旋转超过或位于刻度边界 0 或 100 时，
        // 一定经过一次 0 刻度
        password += (dial != 0 && (temp >= 100 || temp <= 0)) as u32;

        // 计算旋转后刻度的真实位置，刻度值一定大于 0
        dial = temp.rem_euclid(100);
    }

    println!("part2: {password}");
    println!("> Time elapsed is: {:?}", _start.elapsed());
    Ok(password)
}
```

## Day 2

今天要求找出区间内存在重复模式的数字，第一部分要求找出左右两个部分相同的数字，第二部分要求找出数字经过 N 等分后，每个部分都相同的数字。第二部分其实是第一部分的衍生，解题思路在两个部分是一致的。我首先利用暴力法得出题解，通过取余的方法不断的分割数字，对比分割的结果，即可确定是否存在重复模式。暴力法效率不高，因为我遍历了区间内的所有数字，依次检查数字，这样实际效率很慢。

### 渐进寻找

暴力法中区间内的数字是依次递增的，但是应该有更加高效的方法确定符合重复模式的数字。考虑区间 565653-565659 ，可见这个区间中所有的数字都是 6 位等长的，我们先考虑第一部分的重复模式，即数字的前半部分和后半部分应当相同。考虑区间起点 565653 ，直接将区间按照重复模式进行分割，可得到两个数字 565 和 653 ，同样的将结尾也进行分割得到 565 和 659 ，可见两个数字的前半部分相同，那么这个部分就不能变动，那么 653 和 659 就应该变化为 565 ，得到的数字是 565565 不在区间内。所以按照第一部分的匹配模式，无法从区间内寻找到符合的数字。那么考虑第二部分的匹配模式，这个区间的数字长度都为 6 ，那么存在长度为 1、2 和 3 的三种分割模式。确定区间起点和结尾数字中，共同的部分为 56565，那么根据这个共同部分进行分割，可以发现长度 1 或 3 的分割模式是不可能的。考虑分割长度为 2 ，那么分割后每个部分都需要是 56 才行，同时 56 刚好落入起点和结尾 53 - 59 之间，那么长度为 2 的分割可行。

这个方法存在一种情况，那就是如果区间的数字长度不一致，比如区间 95-115 就不容易寻找了，当然可以把区间进行拆分，95-115 变成 95-99 和 100-115 两个区间，分开寻找即可。

**效率对比**

```
part1: 26255179562
> Time elapsed is: 22.953333ms
part2: 31680313976
> Time elapsed is: 37.9495ms
part1 by step: 26255179562
> Time elapsed is: 58.208µs
part2 by step: 31680313976
> Time elapsed is: 70.834µs
```

渐进查找主要代码
```rust
fn split_range(start: usize, end: usize) -> Vec<(usize, usize)> {
    let (start_l, end_l) = (start.ilog10(), end.ilog10());
    if start_l < end_l {
        let mut ranges = vec![];
        let mut start = start;
        for i in start_l..=end_l {
            let new_end = 10usize.pow(i + 1) - 1;
            ranges.push((start, new_end.min(end)));
            start = new_end + 1;
        }
        ranges
    } else {
        vec![(start, end)]
    }
}

fn find_invalid(start: usize, end: usize, base: u32) -> Vec<usize> {
    assert_eq!(start.ilog10(), end.ilog10());
    let l = start.ilog10() + 1;
    if !l.is_multiple_of(base) {
        return vec![];
    }
    let (start_left, end_left) = (start / 10usize.pow(l - base), end / 10usize.pow(l - base));
    let mut invalids = Vec::new();
    for s in start_left..=end_left {
        let n = (0..l)
            .step_by(base as usize)
            .fold(0, |n, i| n + s * 10usize.pow(i));
        if start <= n && n <= end {
            invalids.push(n);
        }
    }
    invalids
}
```

## Day 3

今天要求计算一个数字序列的最大子串（数字），第一部分限定子串长度为2，第二部分则限定长度为12，同时子串的顺序不变。输入的处理不复杂，思路也很简单，就是遍历数字序列，依次寻找最大值即可。

考虑数字序列 96781 ，需要寻找长度为 2 的最大子串，假设子串为 ab ，那么优先从给定序列中确定最大的 a ，同时确保能找到 b 即可。搜索 a 时从左到右进行搜索，而搜索到最后一个数字之前就需要停止，也就是搜索 9678 即可。在搜索 a 的过程中不必考虑是否可能会导致 b 的值不是最大，因为最后的要求的是 ab 最大即可。假设搜索过程中为了确保 b 的值为最大的 d ，而导致 a 取得了较小的值 c，即 c < a 且 d > b ，那么 10 * c + d 一定小于 10 * a + b 。

两个部分对于子串的长度要求不同，但是思路是一致的。从左到右依次搜索字串最大值的过程中，需要记录第一次遇到最大值的元素位置，而非其他可能遇到最大值的位置，这样可以避免影响后续元素最大值搜索。参考序列 98975，需要寻找长度为 2 的最大子串，a 确定搜索到的最大值为 9，如果 a 记录的最大值位置不为 0 而为 2 ，那么搜索 b 时就会从位置 3 开始搜索，最后得到子串为 97 ，是错误结果。

贪心算法核心代码

```rust
fn find_largest_joltage(battery: &[usize], number: usize) -> usize {
    let length = battery.len();
    let mut joltage = 0;
    let mut next_battery = 0;
    for l in (0..number).rev() {
        let mut max_battery = 0;
        (next_battery..(length - l)).for_each(|left| {
            if battery[left] > max_battery {
                max_battery = battery[left];
                next_battery = left + 1;
            }
        });
        joltage = joltage * 10 + max_battery;
    }
    joltage
}
```

这个算法还可以进行剪枝，因为输入的数字序列限制，实际上如果搜索到最大数字为 9 就不需要继续搜索了，这可以进行一定的剪枝，但是我的实现用了 for_each 就具体实现了。

看到一个基本思路一致，但是实现上不同的方法 [ropewalker](https://www.reddit.com/r/adventofcode/comments/1pcvaj4/comment/ns0smcw) [code](https://github.com/ropewalker/advent_of_code_2025/blob/master/src/day03.rs) ，通过滑动限定长度窗口，依次取得最大值，实现不同但算法是一样的，效率应该也没有差别。

目前我的实现在查找过程中实际上存在大量的浪费，因为必须要比较到最后才能确定最大值，而每次查找最大值时都进行了一次。社区上也有人使用 DP 进行优化这个过程，即在一次比较中不断记录当前位置到末尾处的最大值，具体我就不实现了，做一下分析。

阅读社区上他人的动态规划代码 [michel-kraemer](https://github.com/michel-kraemer/adventofcode-rust/blob/main/2025/day03/src/main.rs)，这个实现使用的是自底向上的动态规划，过程中数组 dp 记录的是，长度为 len 的子串从 i 开始的最大子串，转移方程是 dp[len][i] = max(number[i]*mul + dp[len - 1][i + 1])，dp 从长度 1 以及从数字序列最后开始计算。

参考核心代码

```rust
fn dp_find_largest_joltage(battery: &[usize], number: usize) -> usize {
    let length = battery.len();
    let mut dp = vec![vec![0; length + 1]; number + 1];
    let mut mul = 1;
    for len in 1..=number {
        let mut max = 0;
        for (i, &b) in battery.iter().enumerate().take(length - len + 1).rev() {
            max = max.max(b * mul + dp[len - 1][i + 1]);
            dp[len][i] = max;
        }
        mul *= 10;
    }
    dp[number][0]
}
```

理论上 dp 应该要能减少比较的次数，但是这个实现实际的运行效率远不如我的暴力法，对比核心代码实际可以发现比较的次数并没有减少，虽然运行时都是 O(Nk)，N是序列长度，k是子串长度，但是增加了数组操作，整体反而增加了计算成本。比较次数没有减少，是因为每次计算 dp 时，依旧需要从初始位置开始比对到当前的结尾位置，冗余的比较依旧存在。

动态规划算法的核心

- dp[len][i]=从 battery[i..] 中选择 len 个数字，保持相对顺序串联得到的最大值。
- 边界条件（已初始化）：dp[0][i]=0：从任何位置开始选择 0 个数字，结果都是 0。
- 外部循环：按长度 (len) 迭代 `for len in 1..=number` 这个循环是按构建数字的位数从小到大进行计算。DP 算法的关键是利用小规模子问题的解来推导大规模问题的解。在这里，要计算 dp[len][i]，我们必须先知道 dp[len−1][j] 的值。
- 内部循环：按起始索引 (i) 迭代 `for (i, &b) in battery.iter().enumerate().take(length - len + 1).rev()`
- 优化原理：当我们在计算 dp[len][i] 时，我们在考虑从 battery[i..] 中选择 len 个数字。有两种情况：
    - 选择 battery[i] 作为第一个数字： 得到的数字是 battery[i]⋅mul+dp[len−1][i+1]。
    - 不选择 battery[i] 作为第一个数字： 这意味着第一个数字是从 battery[i+1..] 中选的，所以这等价于 dp[len][i+1]。

当前解决的这个特定问题，贪心算法在运行效率（常数时间和空间）上是更优的选择。但在算法设计的普适性上，DP 算法则更为强大。

## Day 04

今天的问题简洁明了，输入是二维的矩阵，其中每个位置上可能存在一卷纸，如果一个卷纸的八个邻接位置上只有小于三个位置上是卷纸时，叉车可以将卷纸移除。第一部分是移除一次，第二部分则是反复进行操作，直到矩阵中所有的卷纸都无法再被移除。问题的核心就是计算矩阵中每个卷纸邻接卷纸的个数，然后根据需求修改矩阵状态。

最直接的思路就是利用二位数组，直接将输入的字符串，转为二维字符数组，接着遍历每一个位置，计算八个邻接位置，判断其中是卷纸的数量。第二部分则需要多次遍历，每次遍历中需要记录移除的卷纸坐标，当一次遍历完成后，根据记录的坐标修改矩阵，将卷纸移除。思路简单明了，也得到了正确的答案，但是我对运行效率不满意，第一部分运行时间是 22ms ，而第二部分则是 273 ms。

第一部分的时间复杂度是 O(N) 其中 N 是矩阵大小，而第二部分的时间复杂度是 O(kN) 其中 k 时可能需要的遍历移除次数，k 最大为最初的卷纸数量。

二维数组模拟输入，实际上非常直观，但是数组存在使用上的局限性，比如八个邻接位置的判断，需要考虑边界条件。同时在这个问题中，第二部分需要搜索的矩阵大小实际上应该是逐渐减小的，而用数组表示则无法利用这个优势。用 HashSet 表示在实现上更加方便，集合只记录所有卷纸的坐标，搜索邻接八个位置时，只需要判断位置是否位于集合中，不必额外考虑坐标边界情况。虽然在实现上更加简便，但是效率却变差了，虽然时间复杂度没有变化，但是 HashSet 的操作更加耗时，最后两部分的运行时间分别是 45ms 和 1s。即便是优化了部分 HashSet 方法的使用，最后的运行时间依旧比不上数组，两部分分别只能做到 48ms 和 437 ms。从第一部分的运行时间差距可以发现，实际上 HashSet 的效率是远比不上数组访问。

### 初步优化（第二部分）

第一部分实际上没有什么优化空间，在这个问题中 Vec 的效率远比 Hash 效率高，优化的主要集中在第二部分。第二部分中移除是分批实现的，即先判断所有的卷纸是否能被移除，然后一次性移除，接着再次判断和移除。这样的实现可以确保结果正确性，但是能否判断一个就移除一个呢？因为所有的卷纸只可能会被移除，不会有新的卷纸产生，如果一个卷纸目前有四个邻接的卷纸，而其中一个卷纸被移除了，那么不需要等到下一次判断，这次就可以一并移除，虽然也会有漏网之鱼，但也能较大的提高运行效率。

实现这个优化采用二维矩阵比 HashSet 更加方便，因为在 Rust 中一边遍历 HashSet 一边又要删除元素是无法实现的（safe），一般来说也不推荐这样做，因为修改遍历对象属于遍历副作用，可能会导致循环无法结束。

在利用 Vec 实现这个优化之后，运行时间并没有大幅下降，第二部分运行时间是 173 ms，差不多少了 100ms。

### 进一步优化

运行效率不高的原因是，在每一个卷纸位置上进行搜索时，需要对领接的八个位置都进行判断，而这个过程又需要反复进行。如果能将搜索邻接位置的结果进行缓存，或者不需要每次都进行判断应该就能大幅降低运行时间。

考虑使用 HashMap 表示输入，其键为卷纸坐标，值为邻接的八个位置中有几个是卷纸。需要提前从输入构筑，初始的邻接搜索必须要进行。每一次搜索时，遇到一个卷纸位置，如果当前卷纸可以被移除，那么邻接八个位置在 HashMap 中的值就需要减 1 。

实际上也可以使用 Vec 二维数组实现，考虑 HashMap 可能存在操作的开销。但是这个思路可以进一步延伸，在搜索一个位置时，如果能提前判断邻接的八个位置是否能被移除，那就可以提前的确定这个卷纸是否能被移除。当然要规避如果 A 移除了，邻接的 B 就能被移除，同时如果 B 被移除，A 也就能被移除，这样的互相限制。

这样的优化终归是局部性的，并不是一劳永逸的，同时是有些盲目的操作。进一步我又想到，实现这个优化最好的数据结构是优先队列，键依旧是坐标，值依旧是邻接的卷纸数量。这个思路看似不错，但是并不容易，因为我需要快速的查找最小值，同时又要求 O(1) 的根据键并修改优先级。可以使用 HashMap + BinaryHeap 实现，HashMap 实时记录位置处邻接卷纸的数量，BinaryHeap 是最小堆，如果堆顶的值大于 4 则说明所有能被移除的卷纸已经被全部移除了。代码具体实现可见 [code](https://github.com/livexia/advent-of-code-2025/commit/3ada45bc2ee0c1cb4a47232aae5d158a766f7660#diff-9babad5b20f1c504f9c4b1d031fd57e6f1a1198343b707f377d777b64c50f47b)，第二部分的运行时间下降到 70ms。

### 使用 BFS 实现

前面的优化实际上就是更加复杂的 BFS ，但是我是在阅读了社区的题解之后才意识到可以使用 BFS 实现。

BFS 也需要用到两个数据结构，VecDeque 和 HashMap ，其中队列中保存的是当前矩阵中邻接卷纸数量小于 4 的卷纸坐标，而 HashMap 则不断记录着每个卷纸的邻接卷纸数量。

每次从队列中弹出卷纸时，更新这个卷纸的邻接卷纸的邻接数量，如果数量小于 4 则将该邻接卷纸入队，依次进行直到队列为空。具体实现见代码 [code](https://github.com/livexia/advent-of-code-2025/blob/main/aoc04/src/main.rs)，第二部分运行时间差不多是 70ms ，这个 BFS 实际上和前面的优化是一致的，所以在时间上没有快很多，但是算法更加简洁实现也更加容易。

因为暴力的方法很简单，所以没有单列与代码中，因为很久没写代码了，所以对于 BFS 有所模糊，最终的代码之保留了 BFS 的实现，BFS 中使用到的 Hash 数据结构也可以通过 Vec 替代，因为输入较小这样也可以提高实际的运行效率，同时提及的运行时间都是 debug 下得到的，release 的运行时间会更少。

## Day 5

今天是区间题，输入分为两个部分，第一部分为区间列表，第二部分为现有 id 列表。第一部分的题目要求计算有多少 id 落在给定的区间中。第一部分简单的暴力循环遍历即可，同样也可以将区间列表合并然后排序，再根据区间起点对 id 进行二分搜索，以降低运行时间提高运行效率，见 [代码](https://github.com/livexia/advent-of-code-2025/commit/f3f498a089d29dda64e26aba6e07ada9a0ccf158)。

第二部分则需要计算所有区间列表中可能的所有 id ，当然不允许重复的 id 。因为给定的区间存在大量重叠的情况，而且由于实际的输入区间较多且较大，那么通过遍历所有区间可能的 id 就不现实了。那么就需要合并区间，而要合并所有区间的第一步就是合并两个区间。

### 合并两个区间

首先根据区间的起点排序并交换给定的两个区间 A 和 B，区间 A 为起点较小的区间，那么如果 A 的终点大于或等于区间 B 的终点，那么合并后的区间就是 A ，如果 A 的终点小于 B 的终点，那么合并后的区间就是 A 的起点到 B 的终点。

题目的**区间是两头都封闭的**，那么如果两个区间头尾相接，则这两个区间也可以合并。
代码

```rust
fn merge_range(r: IdRange, other: IdRange) -> Option<IdRange> {
    let (r, other) = if r.0 > other.0 {
        (other, r)
    } else {
        (r, other)
    };
    if r.1 + 1 < other.0 {
        None
    } else {
        Some((r.0, r.1.max(other.1)))
    }
}
```

### 合并所有的区间

~~我一开始不想使用笨方法，但是简单的几次尝试之后发现都不行，于是使用笨方法得出了答案。存在两个队列，队列 A 是等待合并的区间，队列 B 是已经合并的区间。每次从队 A 弹出一个区间 a，循环遍历队列 B 的区间 b，直到 a 能和 b 合并，将合并后的区间放入队列 B ，直到队列 A 为空。然后交换队列 A 和 B 再次循环，直到没有任何新的合并发生，此时所有的区间都完成了合并，第二部分的答案只需要计算区间的长度即可。~~

经过一番搜索之后，我发现了一个合并所有区间的[算法](https://stackoverflow.com/a/5276789)，我才意识到太久没写代码让我的思维有些慢了，因为明明是很简单算法，没道理我不知道的。

算法

1. 排序 (Sort): 首先按区间的起始点进行排序。
2. 合并 (Merge): 然后遍历排序后的列表。
3. 循环：
    1. 初始区间 current 为排序后的第一个区间
    2. 从排序后的第二个区间开始遍历区间 next。
    3. 如果 current 和 next 可以合并为区间 m，令 current = m 循环继续。
    4. 如果不能合并，则将 current 放入已经完成合并的区间数组，同时令 current = next 循环继续。
        - 具体说明：如果不能合并，则说明 current 和 next 不存在重叠，由于区间是有序的，那么包括 next 之后的所有区间都无法和 current 合并。即 current 已经是确定的完成合并的区间，可以不必再考虑是否能和其他区间合并。
    5. 循环结束后，需要将最后的 current 放入已经完成合并的区间数组，避免遗漏。

代码

```rust
fn merge_ranges(ranges: &[IdRange]) -> Vec<IdRange> {
    let mut ranges = ranges.to_vec();
    ranges.sort();
    let mut merged = vec![];

    let mut current = ranges[0];

    for &next in &ranges[1..] {
        if let Some(m) = merge_range(current, next) {
            current = m;
        } else {
            merged.push(current);
            current = next;
        }
    }
    merged.push(current);
    merged
}
```

## Day 6

今天的题目有点陷阱题的意思，陷阱主要在于输入的处理上，输入类似于表格的形式，看到这个输入立马按照行进行了处理，将一个个数字和运算符解析出来，最终形成两个数组，这样处理之后轻松的就能完成第一部分。


### 列解析与逆序计算

第二部分的核心挑战在于必须采用**逆序的、基于列**的解析方式，而非传统的行处理。为了高效实现这一目标，我们对输入数据进行了预处理，并将运算逻辑与数据累积分离。

#### 1. 数据预处理（逆序化）

* **目标:** 实现从右到左的列迭代。
* **方法:** 对输入文本的每一行（去除空行后），将其**字节序列逆序**。
    * 例如：原输入行 `4 123` 预处理后变为 `[3, 2, 1, ' ' , 4]` (字节表示)。
* **结果:** `lines: Vec<Vec<u8>>` 数组中的列索引 $i$ （从 0 开始）现在对应原始输入中的**从右往左**的列。

#### 2. 核心计算流程（逐列迭代）

代码从 $i=0$ 开始，逐列向左迭代，并在每个列上执行两个主要动作：**数字提取**和**操作符判断**。

##### A. 数字提取 (`real`)

对于当前列 $i$:

1.  **范围:** 仅查看**操作符行之上**的所有行（即除了最后一行）。
2.  **过滤:** 忽略当前列中的所有**空格** (`b' '`) 字符。
3.  **组合:** 将当前列中，从上到下遇到的所有数字字符**组合成一个多位数字** `real`。
    * **公式:** 采用 **`fold(0, |r, n| r * 10 + n)`** 实现，其中 $r$ 是累积结果，$n$ 是当前行数字。

##### B. 操作符判断与计算

检查**最后一行**（操作符行）在当前列 $i$ 上的字符，根据其类型执行相应的逻辑。

| 最后一行字符 | 提取的 `real` 值 | 动作描述 | 对 `ans` 的影响 | `reals` 数组变化 |
| :--- | :--- | :--- | :--- | :--- |
| `b'+'` | 任何值 | **加法运算**。 | $ans += \text{sum}(\text{reals}) + \text{real}$ | 清空 (`reals.clear()`) |
| `b'*'` | 任何值 | **乘法运算**。 | $ans += \text{product}(\text{reals}) \times \text{real}$ | 清空 (`reals.clear()`) |
| 任何其他字符 | $> 0$ | **数字累积**。 | 无 | 推入当前数字 (`reals.push(real)`) |
| 任何字符 | $= 0$ | **序列中断**。 | 无 | 清空 (`reals.clear()`) |

> **`reals` 数组**：用于临时存储在一系列非操作符列中提取到的数字，直到遇到操作符为止。

#### 3. 结果

通过这种逐列、逆序的解析和即时计算，有效地解决了第二部分要求的计算逻辑，避免了复杂的中间数据结构转换，实现了高效的算法。

第二部分代码

```rust
fn part2<T: AsRef<str>>(input: T) -> Result<usize> {
    let _start = Instant::now();

    let mut ans = 0;
    let lines: Vec<Vec<_>> = input
        .as_ref()
        .lines()
        .filter(|l| !l.trim().is_empty())
        .map(|l| l.bytes().rev().collect())
        .collect();
    let op_row = lines.len() - 1;
    let mut reals = vec![];

    for i in 0..lines[0].len() {
        let real = lines[0..op_row]
            .iter()
            .filter_map(|row| {
                if row[i] == b' ' {
                    None
                } else {
                    Some((row[i] - b'0') as usize)
                }
            })
            .fold(0, |r, n| r * 10 + n);
        match lines[op_row][i] {
            b'+' => ans += reals.iter().sum::<usize>() + real,
            b'*' => ans += reals.iter().product::<usize>() * real,
            _ => {
                if real == 0 {
                    reals.clear();
                } else {
                    reals.push(real);
                }
            }
        }
    }

    println!("part 2: {ans}");
    println!("> Time elapsed is: {:?}", _start.elapsed());
    Ok(ans)
}
```

### Day 7

今天的题目难度适中。解题策略清晰：**第一部分**采用 **广度优先搜索 (BFS)**，**第二部分**采用 **深度优先搜索 (DFS)**。

#### 1. BFS 部分：路径查找与去重

对于第一部分，关键在于追踪光束（beams）的移动路径并避免重复计算。

  * 我们使用 **BFS** 来确定所有可能被光束到达的位置。
  * 在 BFS 过程中，必须记录光束**已经到过的位置**，以防止**重复分割**或陷入**死循环**。这相当于使用一个集合（Set/Visited Array）来避免对同一状态的重复探索。

#### 2. DFS 部分：结果缓存与优化

对于第二部分，目标是计算从每个分割点能产生的**平行世界总数**。

  * 我们使用 **DFS** 来递归地计算从任意分割处开始的路径总数。
  * 为提高效率，必须引入**中间结果缓存**（Memoization/动态规划）。我们记录从**任意一个分割处**最终可能分割出的平行世界总数，从而避免重复计算相同子问题。

#### 3. 数据结构的选择与优化

在数据结构的选择上，最初采用 **HashMap** 来表示输入数据是为了简化边界值判断。然而，通过分析题目约束，可以进行优化：

  * 题目保证了光束**不会触发左右边界**，且**只会向下移动**（不会触发顶部边界）。
  * 因此，输入实际上是一个**稀疏矩阵**且移动方向受限，使用**二维向量 (Vec\<Vec\<T\>\>)** 的效率将**显著高于** HashMap，能带来更好的**空间局部性**和更快的访问速度。

今天的题目依旧不难，第一部分很容易想到使用 BFS 完成，而第二部分用 DFS 完成。BFS 中需要记录 beams 已经到过的位置，避免二次分割。DFS 则需要记录从任意一个分割处最终可能分割出多少个平行世界，即需要添加中间结果缓存，以减少计算量。

最开始使用 HashMap 表示输入，这样可以避免边界值判断，但是题目实际上确保了不可能触发左右的边界值，同时只会向下移动，也不会触发顶部的边界情况，实际使用 Vec 应该效率更高。
